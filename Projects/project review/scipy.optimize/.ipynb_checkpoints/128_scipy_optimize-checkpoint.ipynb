{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    " <h1 style=\"text-align: center; color: Maroon; font-family: times; font-size: 30pt;\" >PROJECT 1 <h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    " <h1 style=\"text-align: center; color: black; font-family: Cursive; font-size: 20pt;\" >Optimization & its application with ` scipy.optimize` <h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## I want to use `scipy.optimize` to demonstrate how to address four major kinds of problems: (see the [contents](https://docs.scipy.org/doc/scipy-0.18.1/reference/optimize.html#linear-programming)):\n",
    "\n",
    "1. Minimize 1D functions and find a root of the function in an interval.\n",
    "2. Minimize a function using a nonlinear conjugate gradient algorithm. \n",
    "3. Use non-linear least squares to fit a function, f, to data.\n",
    "4. Optimization with constraints(General constraints)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import scipy.optimize as spo\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 1. Brent's method\n",
    "\n",
    "#### *Brief Introduction\n",
    "In numerical analysis, [Brent's method](https://en.wikipedia.org/wiki/Brent%27s_method) is a root-finding algorithm combining the bisection method, the secant method and inverse quadratic interpolation. \n",
    "\n",
    "Uses the classic Brent’s method to find a zero of the function f on the sign changing interval $[a , b]$. Generally considered the best of the rootfinding routines here. It is a safe version of the secant method that uses inverse quadratic extrapolation.\n",
    "Brent (1973) claims convergence is guaranteed for functions computable within $[a,b]$. [Source](https://docs.scipy.org/doc/scipy-0.18.1/reference/generated/scipy.optimize.brentq.html#scipy.optimize.brentq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### We can use minimize_scalar to minimize scalar function of one variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def g(x):\n",
    "    return np.sin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spo.minimize_scalar(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Soultions are obviously true since the answer fits the attributes of sine function. The smallest value is $-1.0$ when $x = - \\frac{\\pi}{2}$. The pity is that it can only produce one minimal solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Finding root by using [`scipy.optimize.brentq¶`](https://docs.scipy.org/doc/scipy-0.18.1/reference/generated/scipy.optimize.brentq.html#scipy.optimize.brentq)\n",
    "#### Limitations: (1) Function should be continuous. (2) $f(a)$ and $f(b)$ must have opposite signs. (3) In essence, the function is to find only one root of f between a and b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def a(x):\n",
    "    return x**2-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "spo.brentq(a,1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Test solution\n",
    "np.sqrt(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### We can also use [`scipy.optimize.ridder`](https://docs.scipy.org/doc/scipy-0.18.1/reference/generated/scipy.optimize.ridder.html#scipy.optimize.ridder) and [`scipy.optimize.bisect`](https://docs.scipy.org/doc/scipy-0.18.1/reference/generated/scipy.optimize.bisect.html#scipy.optimize.bisect) to minimize scalar function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "spo.ridder(a,1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "spo.bisect(a,1,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2. Conjugate gradient method `scipy.optimize.fmin_cg` to minimize a function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Simple example: Rosenbrock function\n",
    "$$\n",
    "f(x,y) = (a - x)^2 - b(y-x^2)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return .5*(1 - x[0])**2 + (x[1] - x[0]**2)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "spo.fmin_cg(f,[2,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### However, conjugate gradient methods tend to work better when:\n",
    "\n",
    "1. $f$ has a unique global minimizing point, and no local minima or other stationary points,\n",
    "2. $f$ is, at least locally, reasonably well approximated by a quadratic function of the variables,\n",
    "3. $f$ is continuous and has a continuous gradient,\n",
    "4. $fprime$ is not too large, e.g., has a norm less than 1000,\n",
    "5. The initial guess, $x_0$, is reasonably close to $f$ ‘s global minimizing point, xopt.\n",
    "[Citation](https://docs.scipy.org/doc/scipy-0.18.1/reference/generated/scipy.optimize.fmin_cg.html#scipy.optimize.fmin_cg)\n",
    "\n",
    "#### * I will show the function will perform better if the gradient can be passed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def fprime(x):\n",
    "    return np.array((-2*.5*(1 - x[0]) - 4*x[0]*(x[1] - x[0]**2), 2*(x[1] - x[0]**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "spo.fmin_cg(f,[2,2],fprime=fprime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "p.s. We can use [`scipy.optimize.check_grad`](https://docs.scipy.org/doc/scipy-0.18.1/reference/generated/scipy.optimize.check_grad.html#scipy.optimize.check_grad) to check if you have the correct gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "spo.check_grad(f, fprime, [2, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### !!! Obviously, the number of function evalutions has declined significantly, meaning this method working better when given the gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3. Fitting non-linear least-squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "In statistics, non-linear least square is often used to analyze the relationship between two variables. [Definition](https://en.wikipedia.org/wiki/Non-linear_least_squares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pylab as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Example of quadratic function\n",
    "\n",
    "\n",
    "def f(t, alpha, phi):\n",
    "    return 10*alpha*t**2 + phi* t\n",
    "\n",
    "# Our x and y data\n",
    "x = np.linspace(0, 10, 50)\n",
    "y = f(x, 1.5, 1) + .1*np.random.normal(size=50)\n",
    "\n",
    "params, params_cov = spo.curve_fit(f, x, y)\n",
    "# Fit the model\n",
    "spo.curve_fit(f, x, y)\n",
    "\n",
    "# plot the data and the fitted curve\n",
    "t = np.linspace(0, 10, 1000)\n",
    "\n",
    "pl.figure(1)\n",
    "pl.clf()\n",
    "pl.plot(x, y, 'rx')\n",
    "pl.plot(t, f(t, *params), 'b-')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Example of log function\n",
    "\n",
    "\n",
    "def f(t, alpha, phi):\n",
    "    return np.log(alpha*t+phi)\n",
    "\n",
    "# Our x and y data\n",
    "x = np.linspace(0, 10, 50)\n",
    "y = f(x, 1.5, 1) + .1*np.random.normal(size=50)\n",
    "\n",
    "# Fit the model\n",
    "params, params_cov = spo.curve_fit(f, x, y)\n",
    "\n",
    "# plot the data and the fitted curve\n",
    "t = np.linspace(0, 10, 1000)\n",
    "\n",
    "pl.figure(1)\n",
    "pl.clf()\n",
    "pl.plot(x, y, 'rx')\n",
    "pl.plot(t, f(t, *params), 'b-')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Example of sine function\n",
    "\n",
    "np.random.seed(0)\n",
    "# Our test function\n",
    "def f(t, alpha, phi):\n",
    "    return np.sin(alpha*t+phi)\n",
    "\n",
    "\n",
    "x = np.linspace(-3, 3, 50)\n",
    "y = f(x, 1.5, 1) + .1*np.random.normal(size=50)\n",
    "\n",
    "# Fit the model\n",
    "params, params_cov = spo.curve_fit(f, x, y)\n",
    "\n",
    "# plot the data and the fitted curve\n",
    "t = np.linspace(-3, 3, 1000)\n",
    "\n",
    "pl.figure(1)\n",
    "pl.clf()\n",
    "pl.plot(x, y, 'rx')\n",
    "pl.plot(t, f(t, *params), 'b-')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 4. Optimization with Constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "We can use [scipy.optimize.fmin_slsqp¶](http://www.scipy-lectures.org/advanced/mathematical_optimization/) to Minimize a function using Sequential Least SQuares Programming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return np.sqrt((x[0] - 3)**2 + (x[1] - 4)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### define constraint\n",
    "def constraint(x):\n",
    "    return np.atleast_1d(5 - np.sum(np.abs(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "spo.fmin_slsqp(f, np.array([1, 1]), ieqcons=[constraint,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### We can also use [scipy.optimize.fmin_cobyla](http://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.fmin_cobyla.html#scipy.optimize.fmin_cobyla) to minimize a function using the Constrained Optimization BY Linear Approximation (COBYLA) method. This method wraps a FORTRAN implementation of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "spo.fmin_cobyla(f, np.array([1, 1]), cons=constraint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Due to my lack of knowledge of linear programming (I haven't taken MATH 340), this note will not cover linear programming."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
